\relax 
\providecommand\hyper@newdestlabel[2]{}
\citation{FigueroaEtal2012}
\citation{KremplEtAl2014}
\citation{GuptaEtAl2004}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Evaluation}{25}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{evaluation}{{Chapter~4}{25}{Evaluation}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Objectives and measurements}{25}{section.4.1}}
\newlabel{evaluation:objective}{{Section~4.1}{25}{Objectives and measurements}{section.4.1}{}}
\@writefile{brf}{\backcite{FigueroaEtal2012}{{25}{Section~4.1}{section.4.1}}}
\citation{KullbackEtAl1951}
\citation{Joyce2011}
\@writefile{brf}{\backcite{KremplEtAl2014}{{26}{Section~4.1}{equation.4.1.2}}}
\@writefile{brf}{\backcite{GuptaEtAl2004}{{26}{Section~4.1}{equation.4.1.2}}}
\@writefile{brf}{\backcite{KullbackEtAl1951}{{26}{Section~4.1}{equation.4.1.6}}}
\@writefile{brf}{\backcite{Joyce2011}{{26}{Section~4.1}{equation.4.1.6}}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Method selection}{27}{section.4.2}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Summary of all estimators evaluated in the tests}}{27}{table.4.1}}
\newlabel{tab:allEstimators}{{Table~4.1}{27}{Summary of all estimators evaluated in the tests}{table.4.1}{}}
\citation{Dietterich1995}
\citation{FigueroaEtal2012}
\citation{ZhuEtAl2008}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Test environment}{28}{section.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Function models}{28}{subsection.4.3.1}}
\@writefile{brf}{\backcite{Dietterich1995}{{28}{Section~4.3.1}{subsection.4.3.1}}}
\@writefile{brf}{\backcite{FigueroaEtal2012}{{28}{Section~4.3.1}{subsection.4.3.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Active learner}{28}{subsection.4.3.2}}
\@writefile{brf}{\backcite{ZhuEtAl2008}{{29}{Section~4.3.2}{subsection.4.3.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Classifier}{29}{subsection.4.3.3}}
\newlabel{evaluation:classifier}{{Section~4.3.3}{29}{Classifier}{subsection.4.3.3}{}}
\citation{SheatherEtAl1991}
\citation{Silverman1986}
\citation{ArchambeauEtAl2006}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces PAL illustration showing the weighted probabilistic gain (normed on $[0, 1]$). Since all labeled instances are grouped by their class label, the gain is higher for near the lower label-density group}}{30}{figure.4.1}}
\newlabel{fig:PALIllustration}{{Figure~4.1}{30}{PAL illustration showing the weighted probabilistic gain (normed on $[0, 1]$). Since all labeled instances are grouped by their class label, the gain is higher for near the lower label-density group}{figure.4.1}{}}
\newlabel{equ:uniKDE}{{Equation~4.9}{30}{Classifier}{equation.4.3.9}{}}
\@writefile{brf}{\backcite{SheatherEtAl1991}{{30}{Section~4.3.3}{equation.4.3.9}}}
\@writefile{brf}{\backcite{Silverman1986}{{30}{Section~4.3.3}{equation.4.3.9}}}
\@writefile{brf}{\backcite{ArchambeauEtAl2006}{{30}{Section~4.3.3}{figure.4.2}}}
\citation{Chapelle2005}
\citation{KremplEtAl2014}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The estimated kernel density for a grid with one positive and two negative instance; lower Z value indicates lower certainty for the class assignment}}{31}{figure.4.2}}
\newlabel{fig:KDE3inst}{{Figure~4.2}{31}{The estimated kernel density for a grid with one positive and two negative instance; lower Z value indicates lower certainty for the class assignment}{figure.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Datasets}{31}{subsection.4.3.4}}
\@writefile{brf}{\backcite{Chapelle2005}{{31}{Section~4.3.4}{subsection.4.3.4}}}
\citation{CharytanowiczEtAl2010}
\citation{vanDerMaaten2008}
\citation{NashEtAl1994}
\citation{Chapelle2005,KremplEtAl2014,CharytanowiczEtAl2010,NashEtAl1994}
\citation{vanDerMaaten2008}
\citation{Chapelle2005,KremplEtAl2014,CharytanowiczEtAl2010,NashEtAl1994}
\citation{vanDerMaaten2008}
\@writefile{brf}{\backcite{KremplEtAl2014}{{32}{Section~4.3.4}{subsection.4.3.4}}}
\@writefile{brf}{\backcite{CharytanowiczEtAl2010}{{32}{Section~4.3.4}{subsection.4.3.4}}}
\@writefile{brf}{\backcite{vanDerMaaten2008}{{32}{Section~4.3.4}{subsection.4.3.4}}}
\@writefile{brf}{\backcite{NashEtAl1994}{{32}{Section~4.3.4}{subsection.4.3.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Parameters}{32}{subsection.4.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Visualizations of the datasets checke1, 2dData, seeds and a downsized version of abalone \cite  {Chapelle2005,KremplEtAl2014,CharytanowiczEtAl2010,NashEtAl1994}.\newline  The illustration of seeds and abalone was done using an implementation of t-SNE \cite  {vanDerMaaten2008}}}{33}{figure.4.3}}
\@writefile{brf}{\backcite{Chapelle2005}{{33}{Figure~4.3}{figure.4.3}}}
\@writefile{brf}{\backcite{CharytanowiczEtAl2010}{{33}{Figure~4.3}{figure.4.3}}}
\@writefile{brf}{\backcite{KremplEtAl2014}{{33}{Figure~4.3}{figure.4.3}}}
\@writefile{brf}{\backcite{NashEtAl1994}{{33}{Figure~4.3}{figure.4.3}}}
\@writefile{brf}{\backcite{vanDerMaaten2008}{{33}{Figure~4.3}{figure.4.3}}}
\newlabel{fig:datasetIllustrations}{{Figure~4.3}{33}{Visualizations of the datasets checke1, 2dData, seeds and a downsized version of abalone \cite {Chapelle2005,KremplEtAl2014,CharytanowiczEtAl2010,NashEtAl1994}.\newline The illustration of seeds and abalone was done using an implementation of t-SNE \cite {vanDerMaaten2008}}{figure.4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Function-specific parameters for model fitting}}{34}{table.4.2}}
\newlabel{tab:functionParams}{{Table~4.2}{34}{Function-specific parameters for model fitting}{table.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Test results}{34}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Average Mean Error}{34}{subsection.4.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Average mean errors for the different active learners and datasets using the exponential model. The darker colors of a bar mark the errors of later learning stages (bright -> dark: $[3,7]$, $[8,15]$, $[16,30]$ training set size)}}{35}{figure.4.4}}
\newlabel{fig:meanErrorsExp}{{Figure~4.4}{35}{Average mean errors for the different active learners and datasets using the exponential model. The darker colors of a bar mark the errors of later learning stages (bright -> dark: $[3,7]$, $[8,15]$, $[16,30]$ training set size)}{figure.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Average mean errors for the different active learners and datasets using the sigmoid model. The darker colors of a bar mark the errors of later learning stages (bright -> dark: $[3,7]$, $[8,15]$, $[16,30]$ training set size)}}{36}{figure.4.5}}
\newlabel{fig:meanErrorsSig}{{Figure~4.5}{36}{Average mean errors for the different active learners and datasets using the sigmoid model. The darker colors of a bar mark the errors of later learning stages (bright -> dark: $[3,7]$, $[8,15]$, $[16,30]$ training set size)}{figure.4.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Average mean errors for the different active learners and datasets using the linear model. The darker colors of a bar mark the errors of later learning stages (bright -> dark: $[3,7]$, $[8,15]$, $[16,30]$ training set size)}}{37}{figure.4.6}}
\newlabel{fig:meanErrorsLin}{{Figure~4.6}{37}{Average mean errors for the different active learners and datasets using the linear model. The darker colors of a bar mark the errors of later learning stages (bright -> dark: $[3,7]$, $[8,15]$, $[16,30]$ training set size)}{figure.4.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Average mean errors for different datasets with random sampling. The darker colors of a bar mark the errors of later learning stages (bright -> dark: $[3,7]$, $[8,15]$, $[16,30]$ training set size)}}{38}{figure.4.7}}
\newlabel{fig:meanErrorsWeighted}{{Figure~4.7}{38}{Average mean errors for different datasets with random sampling. The darker colors of a bar mark the errors of later learning stages (bright -> dark: $[3,7]$, $[8,15]$, $[16,30]$ training set size)}{figure.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Average squared error}{39}{subsection.4.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Average squared errors for the different active learners, function models and datasets}}{39}{figure.4.8}}
\newlabel{fig:squaredErrors}{{Figure~4.8}{39}{Average squared errors for the different active learners, function models and datasets}{figure.4.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Kernel density estimations from the learning process of PAL for checke1 at 3, 8, 16 and 21 training instances}}{40}{figure.4.9}}
\newlabel{fig:PALKDEs}{{Figure~4.9}{40}{Kernel density estimations from the learning process of PAL for checke1 at 3, 8, 16 and 21 training instances}{figure.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Kullback-Leibler divergence}{40}{subsection.4.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Computation Time}{40}{subsection.4.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Average Kullback-Leibler divergence for selected methods}}{41}{figure.4.10}}
\newlabel{fig:klDiv}{{Figure~4.10}{41}{Average Kullback-Leibler divergence for selected methods}{figure.4.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Left: Average computation times for the estimators. Right: Histogram of computation time for pathSuper}}{42}{figure.4.11}}
\newlabel{fig:compTimeAll}{{Figure~4.11}{42}{Left: Average computation times for the estimators. Right: Histogram of computation time for pathSuper}{figure.4.11}{}}
\@setckpt{chapters/evaluation}{
\setcounter{page}{43}
\setcounter{equation}{9}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{4}
\setcounter{section}{4}
\setcounter{subsection}{4}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{11}
\setcounter{table}{2}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{8}
\setcounter{NAT@ctr}{0}
\setcounter{vrcnt}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{43}
\setcounter{su@anzahl}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{lstnumber}{1}
\setcounter{definition}{0}
\setcounter{theorem}{0}
\setcounter{lemma}{0}
\setcounter{ALG@line}{16}
\setcounter{ALG@rem}{0}
\setcounter{ALG@nested}{0}
\setcounter{ALG@Lnr}{2}
\setcounter{ALG@blocknr}{10}
\setcounter{ALG@storecount}{0}
\setcounter{ALG@tmpcounter}{0}
\setcounter{float@type}{16}
\setcounter{algorithm}{3}
\setcounter{section@level}{2}
\setcounter{lstlisting}{0}
}
